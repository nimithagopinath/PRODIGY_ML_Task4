# Hand Gesture Recognition System
This project aims to develop a Hand gesture recognition model that can accurately identify and classify different hand gestures from image or video data, enabling intuitive human-computer interaction and gesture-based control systems.

# Description
This project aims to develop a Deep Learning Model for Hand Gesture Recognition for gesture-based control systems. The model uses Convolution Neural Networks (CNN) Architecture to extract information from the images.
The model is trained over 15,000 images of hand gestures for about 100 epochs. The model is trained to classify 10 hand gestures given in the dataset:

*    Palm
*    Palm - Moved
*    Fist
*    Fist - Moved
*    Thumb
*    Index
*    OK
*    Down
*    L
*    C

The model produces an accuracy of 88% on the Testing Dataset

# Evaluation

![Training History](https://github.com/LogeswaranSR/PRODIGY_ML_04/assets/131794661/c0ba4cea-0e0e-45b8-a56c-8e0337969b66)


# Inference
![Hand Gesture model Inference](https://github.com/LogeswaranSR/PRODIGY_ML_04/assets/131794661/8f5dba09-3971-4602-b453-536773ef9f12)


# Dataset
The dataset used here is **Hand Gesture Recognition Database** provided by gti-upm in Kaggle. Hand gesture recognition database is composed by a set of near infrared images acquired by the Leap Motion sensor. The database is composed by 10 different hand-gestures (showed above) that were performed by 10 different subjects (5 men and 5 women). The database, as a whole, consists of 20,000 annotated images, separated into folders based on the hand gesture and the subject performed.

Dataset Link: [Hand Gesture Recognition Database](https://www.kaggle.com/datasets/gti-upm/leapgestrecog)
